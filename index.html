<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>April Visual Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="mail to hellonaturia@gmail.com if you want to contect with me">
<meta property="og:type" content="website">
<meta property="og:title" content="April Visual Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="April Visual Blog">
<meta property="og:description" content="mail to hellonaturia@gmail.com if you want to contect with me">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="April Visual Blog">
<meta name="twitter:description" content="mail to hellonaturia@gmail.com if you want to contect with me">
  
    <link rel="alternative" href="/atom.xml" title="April Visual Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://up.qqjia.com/z/12/tu14903_10.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Naturia</a></h1>
		</hgroup>

		
		<p class="header-subtitle">every milestone of study</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>Über</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Homepage</a></li>
				        
							<li><a href="/archives">All Articles</a></li>
				        
							<li><a href="/">Photograph</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Naturia" title="github">github</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100011557206369" title="facebook">facebook</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/jesse-20-70" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">An IT student study image processing these years</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Naturia</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://up.qqjia.com/z/12/tu14903_10.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Naturia</h1>
			</hgroup>
			
			<p class="header-subtitle">every milestone of study</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Homepage</a></li>
		        
					<li><a href="/archives">All Articles</a></li>
		        
					<li><a href="/">Photograph</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Naturia" title="github">github</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100011557206369" title="facebook">facebook</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/jesse-20-70" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-Global-Features" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/14/Global-Features/" class="article-date">
  	<time datetime="2016-03-14T09:41:32.000Z" itemprop="datePublished">2016-03-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/14/Global-Features/">Global Features</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>The main goal of content-based image retrieval is to ﬁnd similar images.While similarity itself is a concept that is hard to formalize, the problem is compounded by the need for comparing millions of images to a query image at search time—a very challenging task. A common approach consists in representing images using the minimal amount of information needed to encode its essential properties.Thisminimal information—called image descriptor—is usually extracted fromthe image’s raw pixel values (and their coordinates)—a process known as feature extraction—and encoded in a numeric vector, the feature vector. Similarity, then, is deﬁned by a suitable metric that computes a distance between two vectors.The design, extraction, and encoding of the image features as well as the choice of the metric makes up for a mathematical representation of visual similarity.</p>
<h3 id="Example-3-1"><a href="#Example-3-1" class="headerlink" title="Example 3.1"></a>Example 3.1</h3><p>Figure 3.5 shows two 4×4 pixels images, I1 and I2. The pixels in these images are either red, yellow, or blue.A simple image feature would consist of counting the colors in the images and assigning the pixel count to dimensions in a vector. Therefore, since there are 7 red pixels, 8 yellow pixels, and 1 blue pixel in the ﬁrst image, I1 = (7, 8, 1). Respectively, the feature vector for the second image is I2 = (8, 4, 4). Knowing both feature vectors a distance function can be applied. A simple function would just sum the absolute differences between components in feature vectors,i.e., |7 − 8|+|8 − 4|+|1 − 4|= 8.Hence, 8 is the quantiﬁcation of difference between the images I1 and I2. (Note that such a distance function is called a L1 distance and will be explained in detail in Section 3.4.)</p>
<p><img src="photo/5.png" alt="co"></p>
<p>Ideally, descriptors should be: (i) representative of the contents of the image (or region) from which they were extracted; (ii) robust to image rotation, scaling, or translation (often referred to as RST invariant in the computer vision literature); and (iii) compact, since the number of dimensions and the range of possible values along each dimension are critical to search time behavior.<br>The naïve color-based descriptor derived in Example 3.1 is somewhat representative of the global contents of the image.One of its obvious limitations is its inability to convey the layout of the colors in each image. It is a rather compact descriptor: the feature vector size is 3, regardless of the size of the image.But what about robustness? A closer inspection shows that, despite its simplicity, it is robust against rotation by angles multiple of 90◦. Scaling, however, leads to a different number of pixels in our example, and therefore to a different feature vector. Inmany cases, scaling operations also change the actual colors of pixels by approximating the color of merged or newly added pixels through their nearest neighbors. Our example feature is also robust against certain cases of translation, e.g., if pixels are switched in their positions, the actual feature vector is not changed.</p>
<h2 id="COLOR-FEATURES"><a href="#COLOR-FEATURES" class="headerlink" title="COLOR FEATURES"></a>COLOR FEATURES</h2><p>“Color is one of the most obvious and pervasive qualities in our environment [26].” It is also a dominant feature in any content-based VIR system, due to the fact that the color information present in an image:</p>
<p>• can be computed in a relatively easy and straightforward way;<br>• is rather robust to background complications; and<br>• is mostly invariant to geometrical transformations, such as resize (scaling) or rotation.</p>
<p>Extracting color-based color features typically involves two main steps: (i) selection of a color model (or color space); and (ii) computation of a descriptor that encodes the color contents of an image—in a compact and discriminative way—according to the chosen color space.</p>
<h3 id="Color-Models"><a href="#Color-Models" class="headerlink" title="Color Models"></a>Color Models</h3><p>A color model (also called color space or color system) is a speciﬁcation of a coordinate system and a subspace within that system where each color is represented by a single point.There have been many different color models proposed over the last 400 years [54]. Some of the most popular color models for VIR are: grayscale, RGB, HSV (and its variations), and HMMD.They are described below.</p>
<h4 id="Grayscale"><a href="#Grayscale" class="headerlink" title="Grayscale"></a>Grayscale</h4><p> The grayscale color model is actually an image representation through which the color information is removed and the intensity of each pixel is computed by: Y = 0.3R +0.6G + 0.1B (where R,G, and B are the red, green, and blue values of each pixel).The weights in this equation were chosen tomodel the human eye’s differences in sensitivity to light stimuli in wavelengths that map to the red, green, and blue colors of the visible spectrum. Grayscale representations are used in VIR systems where the color information was not available in the ﬁrst place (e.g., medical images, such as x-rays and CT scans). They can also be used by popular local visual descriptors, notably SIFT (Scale-Invariance Image Transform),where color doesn’t play any role.</p>
<h4 id="RGB"><a href="#RGB" class="headerlink" title="RGB"></a>RGB</h4><p> The RGB color model is based on a Cartesian coordinate system,whose axes represent the three primary colors of light (R, G, and B), usually normalized to the range [0,1]. This information is usually available directly from the color raster for bitmap images, i.e., once an image ﬁle is read and decoded, no further conversions or calculations are needed to obtain its RGB representation. The number of discrete values of R, G, and B is a function of the pixel depth, deﬁned as the number of bits used to represent each pixel: a typical value is 24 bits (3 color channels × 8 bits per channel). In VIR systems, the R, G, and B values are often (re-)quantized to a much smaller number of values, typically four quantization bins per primary color, resulting in a total of 43 = 64 color combinations. The RGB color model is sometimes expressed in a normalized way, where the normalized colors are denoted r, g, and b and computed as: r = R/R+G+B , g = G/R+G+B , b = B/R+G+B , and r + g + b = 1.Another variant of theRGB colormodel is the opponent color spaceO1,O2,O3, given by<br>                              <img src="photo/6.png" alt="colorfeature"><br>In the opponent color space, the O3 channel represents the intensity information, whereas O1 and O2 encode the color information. The RGB color space and its variants are used in a large number of color descriptors, e.g., color histogram, opponent histogram, rg histogram, RGB-SIFT, OpponentSIFT, C-SIFT,and rgSIFT, among others.</p>
<h4 id="HSV"><a href="#HSV" class="headerlink" title="HSV"></a>HSV</h4><p>The HSV model is part of a family of color models with the ability to dissociate the dimension of intensity (also called brightness or value)fromthe chromaticity—expressed as a combination of hue and saturation—of a color. Other, closely related, color models in this family are: HSI, HSB, and HSL.<br>2 The main advantages of the HSV color model (and its closely related alternatives) are its ability to match the human way of describing colors and to allow for independent control over hue, saturation, and intensity (value). Conversion from RGB (often referred to as sRGB in Java documents) to HSV (referred to as HSB) in Java is quite straightforward due to the availability of methods HSBtoRGB and RGBtoHSB for objects of class java.awt.Color. The HSV color space and its variants are used in several color descriptors, e.g., hue histogram and HSV-SIFT.</p>
<h4 id="HMMD"><a href="#HMMD" class="headerlink" title="HMMD"></a>HMMD</h4><p>The HMMD (Hue-Max-Min-Diff ) color space was developed in connection with<br>MPEG-7 visual descriptors standardization efforts. It is based on the RGB and HSV models and was conceived speciﬁcally for CBIR. The ﬁve components 3 of the HMMD color space are computed as follows:<br>                                 <img src="photo/7.png" alt="colorfeature"></p>
<h4 id="Other-color-models"><a href="#Other-color-models" class="headerlink" title="Other color models:"></a>Other color models:</h4><p>There are many other color models in the image and video processing literature that were not included in this list.The interested readermay want to refer to Chapter 12 of for additional information, including examples in Java.</p>
<h3 id="Color-histograms"><a href="#Color-histograms" class="headerlink" title="Color histograms"></a>Color histograms</h3><p>Color histograms are the most intuitive and the most common visual descriptor. A color histogram is composed of bins each representing the relative amount of pixels of a certain color. Each pixel of an image is assigned to one color bin and increases the respective count. Intuitively, a color image with 16 M different colors would result in a histogram with 16 M bins. To limit the number of dimensions, the color information is typically quantized, so similar colors in the original color space are considered as if they were identical and their frequency of occurrence is computed for the same bin. Color quantization is a critical step in the construction of a feature. The most straightforward color quantization approach consists in dividing the RGB color space into equal-sized partitions, like stacked boxes in 3D space, which has been shown to work rather well.<br>Listing 3.4 gives an example of color quantization in RGB color space.The quantized colors correspond to the deﬁnition of 64-color RGB.</p>
<h4 id="Listing-3-4-Quantization-in-RGB-color-space-to-64-bins"><a href="#Listing-3-4-Quantization-in-RGB-color-space-to-64-bins" class="headerlink" title="Listing 3.4:Quantization in RGB color space to 64 bins"></a>Listing 3.4:Quantization in RGB color space to 64 bins</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int [] histogram = new int[64];</span><br><span class="line">for(int i=0;i&lt;histogram.length;i++)  histogram[i]=0;</span><br><span class="line">BufferedImage img=ImageIO.read(new FileInputStream(&quot;testImage.jpg&quot;));</span><br><span class="line">WritableRaster raster=img.getRaster();</span><br><span class="line">int[] px=new int[3];</span><br><span class="line">for(int x=0;x&lt;raster.getWidth();x++)&#123;</span><br><span class="line">    for(int y=0;y&lt;raster.getHeight();y++)&#123;</span><br><span class="line">        raster.getPixel(x,y,px);</span><br><span class="line">        int pos=(int)Math.round((double)px[2]/85d)+(int)Math.round((double)px[1]/85d)*4+(int)Math.round((double)px[0]/85d)*4*4;</span><br><span class="line">        histogram[pos]++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Fuzzy-color"><a href="#Fuzzy-color" class="headerlink" title="Fuzzy color"></a>Fuzzy color</h4>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Visual-Information-Retrieval-using-Java-and-LIRE-Chapter-2-Summary" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/14/Visual-Information-Retrieval-using-Java-and-LIRE-Chapter-2-Summary/" class="article-date">
  	<time datetime="2016-03-14T07:05:10.000Z" itemprop="datePublished">2016-03-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/14/Visual-Information-Retrieval-using-Java-and-LIRE-Chapter-2-Summary/">Visual Information Retrieval using Java and LIRE:Chapter 2&amp;3</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Visual information retrieval is well grounded in the ﬁeld of information retrieval, which can be described as “the process of searching for (and retrieving) relevant information within a document collection.” Information retrieval is a mature and well-established ﬁeld of research. Visual information retrieval shares the same goals as text-based information retrieval, but focuses on documents containing visual information, i.e., images and videos.<br>The need for information retrieval is as old as the process of producing primitive documents.The ﬁrst document collections date back thousands of years.The ﬁrst (visual) documents currently known are the wall paintings of bison, orses, and other animals in the Cave of Altamira, Spain,estimated to having been produced more than 10,000 years ago.Writing started later and has a long history involving different alphabets andmaterials.Letters and pictogramswerewritten on including silk, stone, clay, parchment, papyrus, and paper.The availability of written documents eventually led to the ﬁrst document collections (archives and libraries).The largest and most signiﬁcant library of the ancient world was the Royal Library of Alexandria founded some time between 305 BC and 283 BC. Along with the ﬁrst libraries, the ﬁrst library organization systems were born. Retrieval in those libraries of course was the work of librarians,who knew how to interpret organization systems,how to use catalogs and indexes and who knew where to ﬁnd what.</p>
<h2 id="BASIC-CONCEPTS-ANDDOCUMENT-REPRESENTATION"><a href="#BASIC-CONCEPTS-ANDDOCUMENT-REPRESENTATION" class="headerlink" title="BASIC CONCEPTS ANDDOCUMENT REPRESENTATION"></a>BASIC CONCEPTS ANDDOCUMENT REPRESENTATION</h2><p>Information retrieval is not about data. Information retrieval is about ﬁnding the information most relevant to a user’s information need.According to there is a clear difference between information and data retrieval.Two of the most dramatic differences are: (i) data retrieval needs a formal, artiﬁcial query language, e.g., SQL, whereas information retrieval deals with natural languages queries; and(ii) data retrieval returns all data matching the query exactly, while information retrieval returns just the best matches and will most likely return incomplete results.<br>Basically, information retrieval deals with <em>documents</em>. The set of available documents is called document corpus. Users, who want to retrieve documents from a corpus, have a particular information need, like “I want to book a hotel in Atlanta next month and I need to ﬁnd the phone number of a suitable hotel to call and reserve a room.” This information need is abstract and not known to the retrieval system. The user just formulates a query, e.g.“hotel Atlanta.” The retrieval system then accesses the index, a data structure for efﬁcient retrieval, where all documents from the corpus are indexed. In information retrieval there is no perfect, or all-true result. So often we settle for “good enough” or “best under the circumstances.” In other words, being “somewhat relevant” is better than nothing.This measure of relevance to the user is called relevance function.It decides numerically how relevant a document is for the user judging on the user query. The most relevant results are then presented to the user.</p>
<h2 id="VECTOR-RETRIEVAL-MODEL"><a href="#VECTOR-RETRIEVAL-MODEL" class="headerlink" title="VECTOR RETRIEVAL MODEL"></a>VECTOR RETRIEVAL MODEL</h2><p>Retrievalmodels [6] provide a solid theoretical framework to design and evaluate new and innovative ideas and to test new approaches. The <em>vector retrieval model</em> is one of the most prominent ones. In the vector retrieval model, documents are points in a vector space. The terms of a corpus span the<br>vector space and the vectors representing documents indicatewhich terms occur inwhich documents.<br>Table 2.1 gives an example document termmatrix of ﬁve documents.The ﬁrst document, for instance,has a term vector of d1 = (2, 0, 1, 0, 0, 0, 0, 0, 2).<br>In the vector retrieval model, the similarity between documents <em>di</em> and <em>dj</em> is typically determined by the <em>cosine coefﬁcient</em> sc(di ,dj ).</p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>                      $$Sc(di,dj)=\frac{di*dj}{|di||dj|}$$<br>In the example at hand the number of occurrences of a term occurs in a document, known as termfrequency, is taken into account.The raw termfrequency tfr (ti ,d) of a termti ∈ d in a document d is the actual number (count) of occurrence of a term.The normalized term frequency is then</p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>                      $$tf(ti,dj)=\frac{tf(ti,d)}{max(tf(t))}$$</p>
<h2 id="TEXT-INFORMATION-RETRIEVAL-WITH-LUCENE"><a href="#TEXT-INFORMATION-RETRIEVAL-WITH-LUCENE" class="headerlink" title="TEXT INFORMATION RETRIEVAL WITH LUCENE"></a>TEXT INFORMATION RETRIEVAL WITH LUCENE</h2><p>Lucene is (i) a prominent open source text retrieval engine written in Java and (ii) the name of a top level Apache project [55]. The Lucene project is organized in several sub projects, whereas LuceneCore is the historical starting point and the originalLucene, the plain text search engine.Several<br>initiatives starting fromLucene havemade to Apache top level projects, like Hadoop, the well known cloud computing solution, and Nutch, the fully ﬂedged web indexing and retrieval solution.<br>At the time of writing this book, Lucene is available in version 4.0 and supports a wide range of professional features including clever index management strategies, scalable and fast indexing, a stable API and integration of many tools necessary for solid text retrieval.The basic data structure in Lucene is the index. It is accessed with implementations of the classes IndexReader for read access and search and IndexWriter for write access. Storage of indexes is managed by implementations of the Directory class, whereas different implementations allow for different storage media, like hard disks, main memory, network, or memory cached indexes.<br>Creating an index and indexing text documents can be done in a few lines of code. Listing 2.1 gives a simple example on how to index text documents with Lucene 4.0. First, an IndexWriter compatible to Lucene version 4.0 is created. The index is written to the directory “index” and uses the SimpleAnalyzer to analyze text in the indexing step (cp. lines 1-3).Note that there aremultiple<br>analyzer implementations available,which allowfor tokenizing, stemming and removal of stopwords. For each document a Lucene Document instance is created (cp. line 6). For each document we add an id and the actual document text. Lucene can either store the text or just retain the indexing data, which reduces size signiﬁcantly (cp. line 7-8). Each document is added to the index (cp. line 9) and ﬁnally the index is closed (cp. line 11).To check if the code works and the index contains everything intended developers can use Luke, 2 an open-source index viewer for Lucene. Luke can show the documents and terms indexed, execute searches, evaluate different analyzer, etc.</p>
<h3 id="Listing-2-1-Simple-example-for-indexing-text-documents-with-Lucene-4-0"><a href="#Listing-2-1-Simple-example-for-indexing-text-documents-with-Lucene-4-0" class="headerlink" title="Listing 2.1:Simple example for indexing text documents with Lucene 4.0"></a>Listing 2.1:Simple example for indexing text documents with Lucene 4.0</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">IndexWriterConfig conf=new IndexWriterConfig(Version.LUCENE_40,new  SimpleAnalyzer(Version.LUCENE_40));</span><br><span class="line">IndexWriter iw=new IndexWriter(FSDirectory.open(new File(&quot;index&quot;)),conf);</span><br><span class="line">for(int i=0;i&lt;document.length;i++)&#123;</span><br><span class="line">    String docText=document[i];</span><br><span class="line">    Document d=new Document();</span><br><span class="line">    d.add(new StringField(&quot;id,&quot;Integer.toString(i),Field.Store.YES));</span><br><span class="line">    d.add(new TextField(&quot;text,&quot;docText,Field.Store.YES));</span><br><span class="line">    iw.addDocument(d);</span><br><span class="line">&#125;</span><br><span class="line">iw.close();</span><br></pre></td></tr></table></figure>
<p>For search with Lucene the class IndexSearcher is used. It needs an IndexReader to access the index and return a TopDocs object instance containing a ranked list of documents from a search. The queries are either created with classes implementing the class Query or parsed from a string using the QueryParser. Listing 2.2 shows a simple example used to search the index created in Listing 2.1.First the IndexReader is used to open the index and the IndexSearcher is created (cp.lines 1-2).The QueryParser is created to be compatible to Lucene version 4.0 and the default ﬁeld named “text” and the default analyzer are given (cp. lines 3-4).The actual search returns a TopDocs<br>instance (cp. line 5). Then results are iterated and the documents’ ids and their relevance scores are printed to System.out (cp. lines 6-9). Note that it is recommended to use the same analyzer for search and for indexing. Otherwise, search will yield unexpected results.</p>
<h3 id="Listing-2-2-Simple-example-for-searching-text-documents-with-Lucene-4-0"><a href="#Listing-2-2-Simple-example-for-searching-text-documents-with-Lucene-4-0" class="headerlink" title="Listing 2.2:Simple example for searching text documents with Lucene 4.0"></a>Listing 2.2:Simple example for searching text documents with Lucene 4.0</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">IndexReader indexReader=DirectoryReader.open(FSDirectory.open(new File(&quot;Index&quot;)));</span><br><span class="line">IndexSearcher is= new IndexSearcher(indexReader);</span><br><span class="line">QueryParser qp=new QueryParser(Version.LUCENE_40,&quot;text,&quot;new SimpleAnalyzer(Version.LUCENE_40));</span><br><span class="line">TopDocs topDocs=is.search(qp.parse(&quot;query string&quot;),5);</span><br><span class="line">for(int i=0;i&lt;topDocs.scoreDocs.length;i++)&#123;</span><br><span class="line"> ScoreDoc scoreDoc=topDocs.scoreDocs[i];</span><br><span class="line"> System.out.println(scoreDoc.score+&quot;:&quot;+indexReader.document(scoreDoc.doc).getValues(&quot;id&quot;)[0]); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Advanced use of Lucene includes distributed indexes, custom relevance functions, stemmers,multi-ﬁeld searches, etc.An extensive discussion of these and other advanced methods can be found in the book Lucene in Action.</p>
<h2 id="DIGITAL-IMAGING-IN-JAVA"><a href="#DIGITAL-IMAGING-IN-JAVA" class="headerlink" title="DIGITAL IMAGING IN JAVA"></a>DIGITAL IMAGING IN JAVA</h2><p>Java, particularly versions 6 and above, includes partial support for reading and writing PNG and JPG image ﬁles through the javax.imageio package. The class javax.imageio.ImageIO provides static convenience methods for reading and writing images. ImageIO.read(…) returns a BufferedImage object,which is the main representation of in-memory images in Java.To read and write pixels of an image one has the access the WritableRaster object within the BufferedImage with the BufferedImage.getRaster() method, which then offers setPixel(…) and getPixel(…) methods. Listing 3.1 gives sample code for opening an image and accessing its pixel values. The provided code prints out the RGB values for the ﬁrst (upper left corner) pixel within the image. Pixel color values are within the [0, 255] range.</p>
<pre><code>    Tablr 3.1: Examples of RGB representation 
|Color name         |Red       |Green     |Blue    |
|-------------------|:--------:|:--------:|:------:|
|red                |1.0       |0.0       |0.0     |
|green              |0.0       |1.0       |0.0     |
|blue               |0.0       |0.0       |1.0     |
|cyan               |0.0       |1.0       |1.0     |
|magenta            |1.0       |0.0       |1.0     |
|yellow             |1.0       |1.0       |0.0     |
|white              |1.0       |1.0       |1.0     |
|black              |0.0       |0.0       |0.0     |
</code></pre><h3 id="Listing-3-1-Opening-an-image-in-Java"><a href="#Listing-3-1-Opening-an-image-in-Java" class="headerlink" title="Listing 3.1: Opening an image in Java"></a>Listing 3.1: Opening an image in Java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">String fileName=&quot;Sample_image.png;&quot;</span><br><span class="line">BufferedImage image=ImageIO.read(new FileInputStream(fileName));</span><br><span class="line">WritableRaster raster=image.getRaster();</span><br><span class="line">int[] tmpPixel=new int[3];</span><br><span class="line">raster.getPixel(0,0,tmpPixel);</span><br><span class="line">System.out.println(&quot;p(0,0)=（&quot;+tmpPixel[0]+,&quot;&quot;+tmpPixel[1]+,&quot;&quot;+tmpPixel[2]+&quot;)&quot;);</span><br></pre></td></tr></table></figure>
<p>It is known that the Java implementation of Oracle does not support JPG ﬁles with color spaces other than RGB. In that case, one might need to employ third party software to decode some JPG ﬁles that cannot be read with the Java runtime. Robust JPEG decoders are integrated in packages such as ImageJ, an image processing and analysis toolkit written in Java.Listing 3.2 shows the code necessary to load and decode an image with ImageJ and to convert it to a BufferedImage instance.</p>
<h3 id="Listing-3-2-Opening-an-image-with-ImageJ"><a href="#Listing-3-2-Opening-an-image-with-ImageJ" class="headerlink" title="Listing 3.2:Opening an image with ImageJ"></a>Listing 3.2:Opening an image with ImageJ</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    public static BufferedImage openImage(String path)&#123;</span><br><span class="line">    ImagePlus imgPlus=new ImagePlus(path);</span><br><span class="line">    //converting the image to RGB</span><br><span class="line">    ImageConverter imageConverter=new ImageConverter(imgPlus);</span><br><span class="line">    imageConverter.convertToRGB();</span><br><span class="line">    //returning the BufferedImage instance</span><br><span class="line">    return imgPlus.getBufferedImage();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Manipulating pixel values (e.g., converting from color to grayscale) and saving the results back to disk is as easy as shown in listing 3.3. Note speciﬁcally in this listing that the int[] array containing the pixel’s values is not created for every pixel, but before that in line 4. This saves time and memory as the same object can be re-used for every pixel of an image.</p>
<h3 id="Listing-3-3-Converting-an-image-to-gray-scale"><a href="#Listing-3-3-Converting-an-image-to-gray-scale" class="headerlink" title="Listing 3.3:Converting an image to gray scale"></a>Listing 3.3:Converting an image to gray scale</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">String fileName=&quot;sample_image.png;&quot;</span><br><span class="line">BufferedImage image=ImageIO.read(new FileInputStream(fileName));</span><br><span class="line">WritableRaster raster=image.getRaster();</span><br><span class="line">int[] tmpPixel=new int[3];</span><br><span class="line">int tmpValue=0;</span><br><span class="line">for(int x=0;x&lt;raster.getWidth();x++)&#123;</span><br><span class="line">    for(int y=0;y&lt;raster.getHeight();y++)&#123;</span><br><span class="line">        raster.getPixel(x,y,tmpPixel);</span><br><span class="line">        tmpValue=(int)(0.3*tmpPixel[0]+0.6*tmpPixel[1]+0.1*tmpPixel[2]);</span><br><span class="line">        tmpPixel[0]=tmpValue;</span><br><span class="line">        tmpPixel[1]=tmpValue;</span><br><span class="line">        tmpPixel[2]=tmpValue;</span><br><span class="line">        raster.setPixel(x,y,tmpPixel);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-image-feature-extraction-summary" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/14/image-feature-extraction-summary/" class="article-date">
  	<time datetime="2016-03-14T03:02:53.000Z" itemprop="datePublished">2016-03-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/14/image-feature-extraction-summary/">Image Feature Extraction:Summary</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Feature extraction is a concept of computer vision and image processing.It refers to using computer to extract information of image as well as decide whether each image point belongs to an image feature.The result of frature extraction is that the points on the image are divided into different subsets,which often belong to the isolated point,oontinuous curve or continuous area.</p>
<p>From wikipedia:<br><em>In machine learning, pattern recognition and in image processing, feature extraction starts from an initial set of measured data and builds derived values (features) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps, and in some cases leading to better human interpretations. Feature extraction is related to dimensionality reduction.</em></p>
<p>Usually we use color feature,texture feature,shape feature and spatial relationship feature as common image features.</p>
<h2 id="Color-feature"><a href="#Color-feature" class="headerlink" title="Color feature"></a>Color feature</h2><h3 id="characteristics"><a href="#characteristics" class="headerlink" title="characteristics:"></a>characteristics:</h3><p>Color feature is a global feature,which describes surface properties of the object in image or image region.General color features are based on the feature of pixels,that all pixels have their own contributions respectively.For color is not sensitive to the direction and the size of the image,it is not very good to capture the local features of the object.In addtion,it happens a lot that many useless images be put forward if we only use color feature in a large database.</p>
<h3 id="Commonly-used-method"><a href="#Commonly-used-method" class="headerlink" title="Commonly used method"></a>Commonly used method</h3><p>Color histogram is the most common way to measure the color feature because of robustness.It won’t be affected by rotation and translation as well as image size if we futher use normalization.The disadvantage is lack of color spatial distribution information.</p>
<h4 id="The-most-commonly-used-color-space"><a href="#The-most-commonly-used-color-space" class="headerlink" title="The most commonly used color space"></a>The most commonly used color space</h4><ul>
<li>RGB color space</li>
<li>HSV color space.</li>
</ul>
<h4 id="Color-histogram-feature-matching-method"><a href="#Color-histogram-feature-matching-method" class="headerlink" title="Color histogram feature matching method"></a>Color histogram feature matching method</h4><ul>
<li>the histogram intersection method</li>
<li>distance method</li>
<li>center distance method</li>
<li>reference color table method</li>
<li>the cumulative color histogram method.</li>
</ul>
<h2 id="Texture-feature"><a href="#Texture-feature" class="headerlink" title="Texture feature"></a>Texture feature</h2><h3 id="characteristics-1"><a href="#characteristics-1" class="headerlink" title="characteristics:"></a>characteristics:</h3><p>Texture feature is also a global feature, and it describes surface properties of the object in the image or image region.But because texture is only an object’s surface properties, and can not completely reflect the nature of the object, so only use the texture feature is unable to get a high level image content. Different from the color feature, texture feature is not based on the characteristics of the pixel, it needs to be included in the region with a number of pixels in order to carry out statistical calculations. In pattern matching, the characteristics of regional appears to be superior, without unsuccess matching because of deviation.<br>As a statistical feature, texture features often have rotation invariance, also perform better in resisting noise. However, it also have shortcomings, one very obvious disadvantage is that when resolution of the image changes, the calculated texture may have a larger deviation.Futher more, due to the impact of light and reflection, the texture from the 2-D image is not necessarily the real texture of the 3-D object.</p>
<h3 id="Commonly-used-method-1"><a href="#Commonly-used-method-1" class="headerlink" title="Commonly used method"></a>Commonly used method</h3><h4 id="Grey-Level-Co-occurrence-Matrix-GLCM"><a href="#Grey-Level-Co-occurrence-Matrix-GLCM" class="headerlink" title="Grey Level Co-occurrence Matrix (GLCM)"></a>Grey Level Co-occurrence Matrix (GLCM)</h4><p>Through experiment,Gotlieb&amp;Kreyszig found that grey level co-occurrence matrix has four key characteristics:weight,inertia,entropy ans correlation.Another typical statiatical methods is to extract texture features using autocorrelation function(i.e.,the image of the energy spectrum function),that is,get texture coarseness and directionality characteristic parameters through energy spectrum function.</p>
<h4 id="geometric-method"><a href="#geometric-method" class="headerlink" title="geometric method"></a>geometric method</h4><ul>
<li>Voronio checkerboard features</li>
<li>Structure feature</li>
</ul>
<h4 id="model-method"><a href="#model-method" class="headerlink" title="model method"></a>model method</h4><ul>
<li>Markov random field （MRF）</li>
<li>Gibbs random field</li>
</ul>
<h4 id="signal-processing-method"><a href="#signal-processing-method" class="headerlink" title="signal processing method"></a>signal processing method</h4><ul>
<li>gray level co-occurrence matrix</li>
<li>Tamura texture feature</li>
<li>auto regressive model</li>
<li>wavelet transform<br>The gray level co-occurrence matrix feature extraction and matching mainly depends on energy, inertia, entropy and correlation between the four parameters. Tamura texture feature based on human visual perception psychology research on texture, puts forward 6 kinds of attributes, namely: roughness, contrast, Degree of orientation, line degree, regularity and rough degree. Auto regressive model (simultaneous auto-regressive SAR) is a Markov random field (MRF) is a kind of application model.</li>
</ul>
<h2 id="Shape-feature"><a href="#Shape-feature" class="headerlink" title="Shape feature"></a>Shape feature</h2><h3 id="characteristics-2"><a href="#characteristics-2" class="headerlink" title="characteristics:"></a>characteristics:</h3><p>It’s effective retrieving interested objects in images that based on shape feature.In general, there are two kinds of representation methods, one is outline feature, the other is the regional feature. The contour feature of the image is mainly aimed at the outer boundary of the object, while the regional feature of the image is related to the whole shape region.</p>
<h3 id="methods"><a href="#methods" class="headerlink" title="methods"></a>methods</h3><h4 id="boundary-feature-method"><a href="#boundary-feature-method" class="headerlink" title="boundary feature method"></a>boundary feature method</h4><ul>
<li>Hough transformation:image gray grandient direction matrix</li>
</ul>
<h4 id="Fourier-shape-descriptors"><a href="#Fourier-shape-descriptors" class="headerlink" title="Fourier shape descriptors"></a>Fourier shape descriptors</h4><ul>
<li>Curvature function</li>
<li>centroid distance</li>
<li>complex coordinate function</li>
</ul>
<h4 id="shape-factor"><a href="#shape-factor" class="headerlink" title="shape factor"></a>shape factor</h4><ul>
<li>Roundness</li>
<li>eccentricity</li>
<li>principal axis</li>
<li>algebraic invariant moments</li>
</ul>
<h3 id="link"><a href="#link" class="headerlink" title="link"></a>link</h3><p><em>[1]<a href="https://en.wikipedia.org/wiki/Feature_extraction" target="_blank" rel="external">https://en.wikipedia.org/wiki/Feature_extraction</a></em><br><em>[2]<a href="http://blog.sina.com.cn/s/blog_4e6680090100d2s9.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4e6680090100d2s9.html</a></em></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-CBIR-I-Introduction" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/13/CBIR-I-Introduction/" class="article-date">
  	<time datetime="2016-03-13T10:44:02.000Z" itemprop="datePublished">2016-03-13</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/13/CBIR-I-Introduction/">CBIR I:Introduction</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Image-Retriving"><a href="#Image-Retriving" class="headerlink" title="Image Retriving"></a>Image Retriving</h2><p>Image retriving is not a newly-born word.Instead,it has been raised for at least ten years.Since 1970s, research on image retrieval has been launched.At that time,it was mainly the Text-based Image Retrieval(TBIR),which uses the text to describe the features of images.For instance,name,time,size,etc.It is widely used until today.Like image.baidu.com.<br>After 1990s,people began to realize the imperfections of TBIR,mostly,in AI.If we don’t know the exact expression about the photo,we just upload it on web,can it feed and provide enough information to us? Therefore CBIR(Content-based Retrieval) was born.It supports analysis and retrieval based on semantic content of the image,like color,layout,texture,etc.Broadly speaking, CBR includes video,audio and other forms of media retrieving.</p>
<h2 id="CBIR"><a href="#CBIR" class="headerlink" title="CBIR"></a>CBIR</h2><p>A typical CBIR system allows users to upload a picture in order to look for other images with the same or similar content.The traditional image retrieval is based on the text,that is, through the name of the picture,text information and the relationship between the index to achieve the query function.<br>The concept has been proposed by T.Kato in 1992.In the paper,he constructed an image database focus on color and shape,and provides a certain search function to carry out the experiment.Since then,the process of content-based image retriving and the concept of CBIR has been  widely used in various research fields,such as statistics,pattern recognition,signal processing and computer vision.<br>Currently,related research has been developed for nearly 20 years.Some traditional search engine companies,including Google,Baidu, Bing have provided a centain content-based image search products.Such as:Google similar image,Baidu search image.</p>
<p>The realization of CBIR relies on four key technologies:<br>1.image feature extraction<br>2.image matching<br>3.database establishing<br>4.database searching</p>
<p>It demands more detailed and deeper inquiry in next several chapters.</p>
<h2 id="Achievements"><a href="#Achievements" class="headerlink" title="Achievements"></a>Achievements</h2><p>The earliest successful CBIR system is QBIC IBM.</p>
<h3 id="Website-link"><a href="#Website-link" class="headerlink" title="Website link:"></a>Website link:</h3><ol>
<li>TinEye<br><a href="http://www.tineye.com/" target="_blank" rel="external">http://www.tineye.com/</a></li>
<li>Google<br><a href="http://images.google.com.hk/" target="_blank" rel="external">http://images.google.com.hk/</a></li>
<li>Baidu<br><a href="http://stu.baidu.com/" target="_blank" rel="external">http://stu.baidu.com/</a></li>
<li>Bing<br><a href="http://www.bing.com/images" target="_blank" rel="external">http://www.bing.com/images</a></li>
<li>Sougou<br><a href="http://pic.sogou.com/" target="_blank" rel="external">http://pic.sogou.com/</a></li>
<li>Yahoo<br><a href="http://images.search.yahoo.com/" target="_blank" rel="external">http://images.search.yahoo.com/</a></li>
<li>Imense<br><a href="http://imense.com/similarsearch/" target="_blank" rel="external">http://imense.com/similarsearch/</a></li>
<li>Macroglossa<br><a href="http://www.macroglossa.com/disclaimer.html" target="_blank" rel="external">http://www.macroglossa.com/disclaimer.html</a></li>
<li>Immenselab<br><a href="http://www.immenselab.com/" target="_blank" rel="external">http://www.immenselab.com/</a></li>
<li>Picsearch<br><a href="http://www.picsearch.com/" target="_blank" rel="external">http://www.picsearch.com/</a></li>
</ol>
<h3 id="Commercial-usage"><a href="#Commercial-usage" class="headerlink" title="Commercial usage:"></a>Commercial usage:</h3><ol>
<li>Like<br><a href="http://www.google.com/shopping" target="_blank" rel="external">http://www.google.com/shopping</a></li>
<li>Ebay<br><a href="http://www.ebay.com/mlt/" target="_blank" rel="external">http://www.ebay.com/mlt/</a></li>
<li>Amazon<br><a href="http://www.a9.com/whatwedo/visual-search/" target="_blank" rel="external">http://www.a9.com/whatwedo/visual-search/</a></li>
<li>TAOTAO search<br><a href="http://www.taotaosou.com/" target="_blank" rel="external">http://www.taotaosou.com/</a></li>
<li>Shopachu<br><a href="http://www.shopachu.com" target="_blank" rel="external">http://www.shopachu.com</a></li>
<li>Chic Engine<br><a href="http://www.chicengine.com/" target="_blank" rel="external">http://www.chicengine.com/</a></li>
<li>Fashionfreax<br><a href="http://lens.fashionfreax.net/zh/" target="_blank" rel="external">http://lens.fashionfreax.net/zh/</a></li>
<li>Incogna<br><a href="http://www.incogna.com/" target="_blank" rel="external">http://www.incogna.com/</a></li>
</ol>
<h3 id="Mobile-APP"><a href="#Mobile-APP" class="headerlink" title="Mobile || APP"></a>Mobile || APP</h3><ol>
<li>Google Goggles<br><a href="http://www.google.com/mobile/goggles" target="_blank" rel="external">http://www.google.com/mobile/goggles</a></li>
<li>Kooaba<br><a href="http://www.kooaba.com/en/apps" target="_blank" rel="external">http://www.kooaba.com/en/apps</a></li>
<li>SnapTell<br>SnapTell for iPhone</li>
<li>Pixlinq<br><a href="http://www.pixlinq.com/home" target="_blank" rel="external">http://www.pixlinq.com/home</a></li>
<li>Digimarc Discover<br><a href="http://www.digimarc.com/discover" target="_blank" rel="external">http://www.digimarc.com/discover</a></li>
<li>Picitup<br><a href="http://www2.picitup.com/" target="_blank" rel="external">http://www2.picitup.com/</a></li>
<li>Recognize<br><a href="https://www.recognize.im/" target="_blank" rel="external">https://www.recognize.im/</a></li>
<li>LTU Mobile<br><a href="http://www.ltutech.com/solutions/mobile-visual-search/" target="_blank" rel="external">http://www.ltutech.com/solutions/mobile-visual-search/</a></li>
<li>Fashionfreax<br><a href="http://lens.fashionfreax.net/zh/" target="_blank" rel="external">http://lens.fashionfreax.net/zh/</a></li>
<li>Baidu APP</li>
<li>ARART<br><a href="http://arart.info/" target="_blank" rel="external">http://arart.info/</a></li>
</ol>
<p>More CBIR search engines:  <a href="http://en.wikipedia.org/wiki/List_of_CBIR_engines" target="_blank" rel="external">http://en.wikipedia.org/wiki/List_of_CBIR_engines</a><br>CBIR experimental systems: <a href="http://www.icvpr.com/cbir-systems/" target="_blank" rel="external">http://www.icvpr.com/cbir-systems/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-A-smart-puzzlegame" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/13/A-smart-puzzlegame/" class="article-date">
  	<time datetime="2016-03-13T07:49:01.000Z" itemprop="datePublished">2016-03-13</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/13/A-smart-puzzlegame/">A smart puzzle game</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>These two weeks,we learned how to develop a web game using JS&amp;HTML5. I adapted the code of puzzle game and trying to improve its intelligence.It can tell you what in the picture after u finish the game. Let me show you now.</p>
<h2 id="Let’s-start"><a href="#Let’s-start" class="headerlink" title="Let’s  start"></a>Let’s  start</h2><p>You can access the game by the link <a href="http://naturia.coding.me/PuzzleGame" target="_blank" rel="external">ImagePuzzle</a><br>This is the very first image you may see on the game.Now we have to restore the image and complete the game.The game divides difficulty into easy,medium and hard levels.Enjoy it!</p>
<p><img src="photo/1.png" alt="puzzlegame"></p>
<h2 id="Completed"><a href="#Completed" class="headerlink" title="Completed"></a>Completed</h2><p>Congratulations!We have finished the game now.<br>it tells us that the image is a rabbit.And there are three buttons.</p>
<p><img src="photo/2.png" alt="Now finished"></p>
<h2 id="About"><a href="#About" class="headerlink" title="About"></a>About</h2><p>Click “About” button we can jump to wikipedia/Rabbit page.It can tells us about little rabbit in a variety of aspects.</p>
<p><img src="photo/3.png" alt="About"></p>
<h2 id="Search-more"><a href="#Search-more" class="headerlink" title="Search more"></a>Search more</h2><p>   Click “Search more” we can get more pictures about rabbit.</p>
<p>   Click “play again” we can continue the game.</p>
<p><img src="photo/4.png" alt="Search more"></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>   HTML5 main code as follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">    var images = [</span><br><span class="line">        &#123; src: &apos;Big_ben.jpg&apos;, title: &apos;1&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Cat.jpg&apos;, title: &apos;2&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Cherry_blossom.jpg&apos;, title: &apos;3&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Deer.jpg&apos;, title: &apos;4&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Dog.jpg&apos;, title: &apos;5&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Helianthus.jpg&apos;, title: &apos;6&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Lake.jpg&apos;, title: &apos;7&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Lavandula.jpg&apos;, title: &apos;8&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Lily_of_the_valley.jpg&apos;, title: &apos;9&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Malus_spectabilis.jpg&apos;, title: &apos;10&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Mushroom.jpg&apos;, title: &apos;11&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Pear.jpg&apos;, title: &apos;12&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Prague.jpg&apos;, title: &apos;13&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Prairie.jpg&apos;, title: &apos;14&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Provence.jpg&apos;, title: &apos;15&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Rabbit.jpg&apos;, title: &apos;16&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Raccoon.jpg&apos;, title: &apos;17&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Sheep.jpg&apos;, title: &apos;18&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Taj_Mahal.jpg&apos;, title: &apos;19&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Venice.jpg&apos;, title: &apos;20&apos; &#125;,</span><br><span class="line">        &#123; src: &apos;Wharf.jpg&apos;, title: &apos;21&apos; &#125;</span><br><span class="line"></span><br><span class="line">    ];</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    $(function () &#123;</span><br><span class="line">        var gridSize = $(&apos;#levelPanel :radio:checked&apos;).val();</span><br><span class="line">        imagePuzzle.startGame(images, gridSize);</span><br><span class="line">        $(&apos;#newPhoto&apos;).click(function () &#123;</span><br><span class="line">            var gridSize = $(&apos;#levelPanel :radio:checked&apos;).val();  // Take the updated gridSize from UI.</span><br><span class="line">            imagePuzzle.startGame(images, gridSize);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        $(&apos;#levelPanel :radio&apos;).change(function (e) &#123;</span><br><span class="line">            var gridSize = $(this).val();</span><br><span class="line">            imagePuzzle.startGame(images, gridSize);</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">    &#125;);</span><br><span class="line">    function jumpWiki() &#123;</span><br><span class="line">        var path = images[$(&quot;#imgTitle&quot;).html() - 1].src</span><br><span class="line">        var name = path.substring(0, path.indexOf(&quot;.&quot;))</span><br><span class="line">        window.open(&quot;http://en.wikipedia.org/wiki/&quot; + name)</span><br><span class="line">    &#125;</span><br><span class="line">    function jumpBaidu() &#123;</span><br><span class="line">        var path = images[$(&quot;#imgTitle&quot;).html() - 1].src</span><br><span class="line">        var name = path.substring(0, path.indexOf(&quot;.&quot;))</span><br><span class="line">        window.open(&quot;http://cn.bing.com/images/search?q=&quot; + name)</span><br><span class="line">    &#125;</span><br><span class="line">    function rules() &#123;</span><br><span class="line">        alert(&apos;Re arrange the image parts in a way that it correctly forms the picture. \nThe no. of steps taken will be counted.&apos;);</span><br><span class="line">    &#125;</span><br><span class="line">    function about() &#123;</span><br><span class="line">        alert(&apos;Developed by Jesse Wang. \nShe can be contacted at: hellonaturia@gmail.com&apos;);</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>
<p><em>In this part it’s clear that we just pre-set and label every picture,the label is related to its name.So if you finish the game,it can jump to the link with the name as the suffix.</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">              &lt;button type=&quot;button&quot; onclick=&quot;jumpWiki()&quot; target=&quot;_blank&quot;&gt;About&lt;/button&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">          &lt;br/&gt;</span><br><span class="line">         &lt;div&gt;</span><br><span class="line">              &lt;button type=&quot;button&quot; onclick=&quot;jumpBaidu()&quot; target=&quot;_blank&quot;&gt;Search more&lt;/button&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">          &lt;br/&gt;</span><br><span class="line"></span><br><span class="line">          &lt;div&gt;</span><br><span class="line">              &lt;button type=&quot;button&quot; onclick=&quot;window.location.reload(true);&quot;&gt;Play Again&lt;/button&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p><em>This is the control process</em><br>Now you know the principle and limits of the program,actually it’s not AI but i’m trying to make it more like identifying itself.It’s far from to the end.By the way,Thanks a lot to Dashen^_^</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/13/hello-world/" class="article-date">
  	<time datetime="2016-03-13T02:11:26.127Z" itemprop="datePublished">2016-03-13</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/13/hello-world/">Blog Introduction</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://april.science/" target="_blank" rel="external">April Visual Blog</a>! This is my very first post. In this article i would like to introduce the content and structure of my blog briefly.</p>
<h2 id="THEME-amp-SUBJECT"><a href="#THEME-amp-SUBJECT" class="headerlink" title="THEME &amp; SUBJECT"></a>THEME &amp; SUBJECT</h2><p>The blog is oriented to computer vision field.<br>According to wikipedia definition:”Computer vision is a field that includes methods for acquiring, processing, analyzing, and understanding images and, in general, high-dimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions.”<br>To writing the blog,i will mainly focus on image processing and retrieving, there are many interesting and important algorithms related to it. Actually it is part of my project this year. Therefore every step of my effort that counts.</p>
<h2 id="CONTENT"><a href="#CONTENT" class="headerlink" title="CONTENT"></a>CONTENT</h2><p>1.Article<br>2.Essay<br>3.program &amp; source code<br>4.image<br>etc.</p>
<h2 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h2><p>If there is any problem, feel free to contact me by hellonaturia@gmail.com.Thanks for your visit and reading.</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Naturia
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>